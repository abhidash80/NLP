{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda120e2-328a-4b02-8067-9cf9bd7e696e",
   "metadata": {},
   "source": [
    "### Named Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d6e7b1-3638-4ded-a2b2-ea87fef9a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\" On January 15, 2024, Abhijit Dash from Chennai joined FICO as a Senior Software Engineer to work on AI-driven credit risk models for banks in India and Southeast Asia. He collaborated with teams in Bangalore, Singapore, and London to build machine learning solutions for fraud detection and loan approval. The project was funded by the World Bank and supported by the Reserve Bank of India to improve financial inclusion.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864a76fd-a4fe-47f9-af2a-8f54bc9b74b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPerson: Abhijit\\nPlace\\nDate\\nOrganization\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Person: Abhijit\n",
    "Place\n",
    "Date\n",
    "Organization\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660b1ede-1495-4e08-a6eb-3aa085727b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "words=nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a80e56-7180-4b41-b587-4d1760044be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abhijitdash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/abhijitdash/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/abhijitdash/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/abhijitdash/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b01fe79-cf03-4cb3-96e5-215602b5f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_con = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8639042f-6d66-4715-a5e5-cfd4a799d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nltk.ne_chunk(tag_con)#Use NLTK's currently recommended named entity chunker to chunk the given list of tagged tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282f3c37-3b5b-4e09-bc00-99b16343ec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON : Abhijit Dash\n",
      "PERSON : Chennai\n",
      "ORGANIZATION : FICO\n",
      "ORGANIZATION : Senior Software Engineer\n",
      "GPE : India\n",
      "LOCATION : Southeast Asia\n",
      "GPE : Bangalore\n",
      "GPE : Singapore\n",
      "GPE : London\n",
      "ORGANIZATION : World Bank\n",
      "ORGANIZATION : Reserve Bank\n",
      "GPE : India\n"
     ]
    }
   ],
   "source": [
    "for chunk in ner:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        print(chunk.label(), \":\", \" \".join(c[0] for c in chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4bbfa-8dad-48f8-a486-7890a0e21ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
